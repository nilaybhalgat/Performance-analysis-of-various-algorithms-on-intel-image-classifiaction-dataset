{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.layers as Layers\nimport tensorflow.keras.activations as Activations\nimport tensorflow.keras.models as Models\nimport tensorflow.keras.optimizers as Optimizer\nimport keras \nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nimport time\nimport pandas as pd\nfrom sklearn.utils import shuffle\nfrom IPython.display import SVG\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest'] \nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}  \nnb_classes = len(class_names)  \nIMAGE_SIZE = (32, 32)\nIMAGE_SIZE1 = (150, 150)  \n# Image sizes used are different for different algoritms.\n# for NN and CNN size is 64*64\n# for InceptionV3 and VGG are 150*150\n# for other algoritmhms is 32*32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data():\n    datasets = ['../input/intel-image-classification/seg_train/seg_train', '../input/intel-image-classification/seg_test/seg_test']\n    output = []\n   \n    # Iterate through training and test sets\n    for dataset in datasets:\n       \n        images = []\n        labels = []\n       \n        print(\"Loading {}\".format(dataset))\n       \n        # Iterate through each folder corresponding to a category\n        for folder in os.listdir(dataset):\n            label = class_names_label[folder]\n           \n            # Iterate through each image in our folder\n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n               \n                # Get the path name of the image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n               \n                # Open and resize the img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE)\n               \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n               \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')  \n        print(images.shape)\n        output.append((images, labels))\n\n    return output\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data1():\n   \n    datasets = ['../input/intel-image-classification/seg_train/seg_train', '../input/intel-image-classification/seg_test/seg_test']\n    output = []\n   \n    # Iterate through training and test sets\n    for dataset in datasets:\n       \n        images = []\n        labels = []\n       \n        print(\"Loading {}\".format(dataset))\n       \n        # Iterate through each folder corresponding to a category\n        for folder in os.listdir(dataset):\n            label = class_names_label[folder]\n           \n            # Iterate through each image in our folder\n            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n               \n                # Get the path name of the image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n               \n                # Open and resize the img\n                image = cv2.imread(img_path)\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                image = cv2.resize(image, IMAGE_SIZE1)\n               \n                # Append the image and its corresponding label to the output\n                images.append(image)\n                labels.append(label)\n               \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')  \n        print(images.shape)\n        output.append((images, labels))\n\n    return output\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_images, train_labels), (X_test, y_test) = load_data()  \nX_train, y_train = shuffle(train_images, train_labels, random_state=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_images1, train_labels1), (Xnn_test, ynn_test) = load_data1()  \nXnn_train, ynn_train = shuffle(train_images1, train_labels1, random_state=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaling is done by dividing each value by 255 and each value will be in range 0 and 1\n# for CNN NN InceptionV3 and VGG input are 4D arrays\n# for others are 2D array\n\nXnn_train = Xnn_train/255\nXnn_test = Xnn_test/255\nprint(Xnn_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.reshape(X_train.shape[0],32*32*3) \nX_test = X_test.reshape(X_test.shape[0],32*32*3) \nX_train = X_train/255; \nX_test = X_test/255;\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Code for logistic regression\nfrom sklearn.linear_model import LogisticRegression\ntic = time.time()\nlog_reg = LogisticRegression(solver='lbfgs',multi_class='multinomial',max_iter = 10000)\nlog_reg.fit(X_train,y_train)\npredlr = log_reg.predict(X_test)\nprint(accuracy_score(predlr,y_test))\ntoc = time.time()\nLRtime = toc-tic\nprint(LRtime)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# code for naive bayes with linear \nfrom sklearn.naive_bayes import MultinomialNB\ntic = time.time()\nNB = MultinomialNB()\nNB.fit(X_train,y_train)\nprednb = NB.predict(X_test)\nprint(accuracy_score(prednb,y_test))\ntoc = time.time()\nNBtime = toc-tic\nprint(NBtime)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# code for naive bayes with gaussian\nfrom sklearn.naive_bayes import GaussianNB\ntic = time.time()\nGNB = GaussianNB()\nGNB.fit(X_train,y_train)\npredgnb = GNB.predict(X_test)\nprint(accuracy_score(predgnb,y_test))\ntoc = time.time()\nNBtime = toc-tic\nprint(NBtime)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ntic = time.time()\ndt = DecisionTreeClassifier()\ndt.fit(X_train,y_train)\npreddt = dt.predict(X_test)\nprint(accuracy_score(preddt,y_test))\ntoc = time.time()\nKNNtime = toc-tic\nprint(KNNtime)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\ntic = time.time()\nknn = KNeighborsClassifier(n_neighbors = 6)\nknn.fit(X_train,y_train)\npredknn = knn.predict(X_test)\nprint(accuracy_score(predknn,y_test))\ntoc = time.time()\nKNNtime = toc-tic\nprint(KNNtime)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\ntic = time.time()\nmodel2 =Sequential([\n    keras.layers.Flatten( input_shape = (64,64,3)),\n    keras.layers.Dense(64*3, activation= 'relu' ),\n    keras.layers.Dense(64, activation= 'relu' ),\n    keras.layers.Dense(32, activation= 'relu' ),\n    keras.layers.Dense(6, activation= 'softmax')\n    \n])\n\nmodel2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n\nhistory2 = model2.fit(Xnn_train, ynn_train, batch_size=128, epochs=16, validation_split = 0.2)\n\ntoc = time.time()\nNNtime = toc-tic\nprint(NNtime)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.evaluate(Xnn_test,ynn_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tic = time.time()\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = (64, 64, 3)), \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])\nmodel.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(Xnn_train, ynn_train, batch_size=128, epochs=10, validation_split = 0.2)\ntoc = time.time()\nCNNtime = toc-tic\nprint(CNNtime)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(Xnn_test,ynn_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tic = time.time()\nimport xgboost as xgb\nxg_cl = xgb.XGBClassifier(objective='multi:softprob',\nn_estimators=10, seed=123)\nxg_cl.fit(X_train, y_train)\npreds = xg_cl.predict(X_test)\naccuracy = float(np.sum(preds==y_test))/y_test.shape[0]\nprint(accuracy)\ntoc = time.time()\nXGBtime = toc-tic\nprint(XGBtime)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\ntic = time.time()\nclf=RandomForestClassifier(n_estimators=100)\nclf.fit(X_train, y_train)  \ny_pred=clf.predict(X_test)\nfrom sklearn import metrics  \nprint(\"Accuracy:\",metrics.accuracy _score(y_test, y_pred))\ntoc = time.time()\nRFtime = toc-tic\nprint(RFtime)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\ntic = time.time()\npca = PCA(n_components=500)\npca.fit_transform(X_train)\nprint(pca.explained_variance_ratio_.sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm = SVC()\nsvm.fit(X_train,y_train)\npredsvm = svm.predict(X_test)\ntoc = time.time()\nsvmtime = toc-tic\nprint(svmtime)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy:\",metrics.accuracy_score(y_test, predsvm))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.optimizers import RMSprop\n\nlocal_weights_file = '/kaggle/input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\npre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n                                include_top = False, \n                                weights = None)\n\npre_trained_model.load_weights(local_weights_file)\n\nfor layer in pre_trained_model.layers:\n     layer.trainable = False\n        \n\n\nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\nx = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(6, activation='softmax')(x)           \n\nmodel = Model(pre_trained_model.input, x) \n\nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'sparse_categorical_crossentropy', \n              metrics = ['acc'])\n\nhistory=model.fit(Xnn_train,ynn_train,epochs=1,validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(Xnn_test,ynn_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfile='/kaggle/input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\npretrained_model=VGG16(input_shape = (150, 150, 3), \n                        include_top = False, \n                        weights =None)\npretrained_model.load_weights(file)\n\nfor layer in pretrained_model.layers:\n     layer.trainable = False\n\nlast_layer = pretrained_model.get_layer('block5_pool')\nprint('last layer of vgg : output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\ny = layers.Flatten()(last_output)\ny = layers.Dense(1024, activation='relu')(y)\ny = layers.Dropout(0.2)(y)                  \ny = layers.Dense(6, activation='softmax')(y)           \n\nmodel_vgg = Model(pretrained_model.input, y) \n\n\nmodel_vgg.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'sparse_categorical_crossentropy', \n              metrics = ['acc'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_vgg.fit(Xnn_train,ynn_train,epochs=1,validation_split=0.2)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}